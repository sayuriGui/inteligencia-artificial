{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KF7vMKCYg-An"
   },
   "source": [
    "# Actividad: Ajuste de redes neuronales\n",
    "## Tania Sayuri Guizado Hernández\n",
    "### Ejercicio 1 (50 puntos)\n",
    "El conjunto de datos de criminalidad de Estados Unidos publicado en el año 1993 consiste de 51 registros para los que se tienen las siguientes variables:\n",
    "\n",
    "- VR = crímenes violentos por cada 100000 habitantes\n",
    "- MR = asesinatos por cada 100000 habitantes\n",
    "- M = porcentaje de áreas metropolitanas\n",
    "- W = porcentaje de gente blanca\n",
    "- H = porcentaje de personas con preparatoria terminada\n",
    "- P = porcentaje con ingresos por debajo del nivel de pobreza\n",
    "- S = porcentaje de familias con solo un miembro adulto como tutor\n",
    "\n",
    "Para este conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "HlfrfIJ_NLLo"
   },
   "outputs": [],
   "source": [
    "#Cargamos las librerías que se usaran en la actividad\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, GridSearchCV, KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report,mean_squared_error, mean_absolute_error\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('crime_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXCTeWzMhS8o"
   },
   "source": [
    "### 1-.Evalúa con validación cruzada un modelo pereceptrón multicapa para las variables que se te asignaron para este ejercicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iXn16X9wg_Co"
   },
   "outputs": [],
   "source": [
    "x = np.array(df[['M', 'W', 'S', 'P']])\n",
    "y = np.array(df['VR'])\n",
    "n_features = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sIIj1K3tzV1S"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1iTaroY5hpGF",
    "outputId": "dea8b054-4e42-4cf9-ef6d-23831987a8ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.7265824647595412\n",
      "MAE:  0.5077574500355346\n",
      "MSE: 80420.05778311426   MAE: 211.065184562885\n"
     ]
    }
   ],
   "source": [
    "clf = MLPRegressor(hidden_layer_sizes=(20, 20), max_iter=200000)\n",
    "clf.fit(X_scaled, y)\n",
    "y_pred = clf.predict(X_scaled)\n",
    "print('MSE: ', mean_squared_error(y, y_pred))\n",
    "print(\"MAE: \", mean_absolute_error(y, y_pred))\n",
    "kf = KFold(n_splits=5)\n",
    "mse_cv = []\n",
    "mae_cv = []\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "    # Training phase\n",
    "    x_train = X_scaled[train_index, :]\n",
    "    y_train = y[train_index]\n",
    "    clf_cv = MLPRegressor(hidden_layer_sizes=(20, 20), max_iter=20000)\n",
    "    clf_cv.fit(x_train, y_train)\n",
    "    # Test phase\n",
    "    x_test = X_scaled[test_index, :]\n",
    "    y_test = y[test_index]\n",
    "    y_pred = clf_cv.predict(x_test)\n",
    "    mse_i = mean_squared_error(y_test, y_pred)\n",
    "    mse_cv.append(mse_i)    \n",
    "    mae_i = mean_absolute_error(y_test, y_pred)  \n",
    "    mae_cv.append(mae_i)\n",
    "   \n",
    "print('MSE:', np.average(mse_cv), '  MAE:', np.average(mae_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgiMqzhXhcGK"
   },
   "source": [
    "### 2-. Agrega al conjunto de datos columnas que representen los cuadrados de las variables predictoras (por ejemplo, M2, W2), así como los productos entre pares de variables (por ejemplo, PxS, MxW). Evalúa un modelo perceptrón multicapa para este nuevo conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YbqHNtXXhgG9"
   },
   "outputs": [],
   "source": [
    "df['M2'] = df['M'] ** 2\n",
    "df['W2'] = df['W'] ** 2\n",
    "df['S2'] = df['S'] ** 2\n",
    "df['P2'] = df['P'] ** 2\n",
    "df['MW'] = df['M'] * df['W']\n",
    "df['MS'] = df['M'] * df['S']\n",
    "df['MP'] = df['M'] * df['P']\n",
    "df['WS'] = df['W'] * df['S']\n",
    "df['WP'] = df['W'] * df['P']\n",
    "df['SP'] = df['S'] * df['P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mn-XnV9b2uKA"
   },
   "outputs": [],
   "source": [
    "x2 = np.array(df[['M', 'W', 'S', 'P', 'M2', 'W2', 'S2','P2','MW','MS','MP','WS','WP','SP']])\n",
    "y2 = np.array(df['VR'])\n",
    "n_features = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Fh3fVPYB28gk"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X2_scaled = scaler.fit_transform(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "esoKGjCB3IYS",
    "outputId": "158178dc-b1b9-4f9b-d45f-7fdc51c50591"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.615828330096692\n",
      "MAE:  0.3314057222664132\n",
      "MSE: 174794.3032661454   MAE: 245.06165990274872\n"
     ]
    }
   ],
   "source": [
    "clf = MLPRegressor(hidden_layer_sizes=(20, 20), max_iter=20000)\n",
    "clf.fit(X2_scaled, y)\n",
    "y_pred = clf.predict(X2_scaled)\n",
    "print('MSE: ', mean_squared_error(y, y_pred))\n",
    "print(\"MAE: \", mean_absolute_error(y, y_pred))\n",
    "kf = KFold(n_splits=5)\n",
    "mse_cv = []\n",
    "mae_cv = []\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "    # Training phase\n",
    "    x_train = X2_scaled[train_index, :]\n",
    "    y_train = y[train_index]\n",
    "    clf_cv = MLPRegressor(hidden_layer_sizes=(20, 20), max_iter=20000)\n",
    "    clf_cv.fit(x_train, y_train)\n",
    "    # Test phase\n",
    "    x_test = X2_scaled[test_index, :]\n",
    "    y_test = y[test_index]\n",
    "    y_pred = clf_cv.predict(x_test)\n",
    "    mse_i = mean_squared_error(y_test, y_pred)\n",
    "    mse_cv.append(mse_i)    \n",
    "    mae_i = mean_absolute_error(y_test, y_pred)  \n",
    "    mae_cv.append(mae_i)\n",
    "    \n",
    "print('MSE:', np.average(mse_cv), '  MAE:', np.average(mae_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-. Viendo los resultados de regresión, desarrolla una conclusión sobre los siguientes puntos:\n",
    "- ¿Consideras que el modelo perceptrón multicapa es efectivo para modelar los datos del problema? ¿Por qué?\n",
    "\n",
    "En base a los resultados obtenidos, puedo concluir que el modelo perceptrón multicapa tiene más efectividad en el modelado de datos de ambos problemas (con las variables originales y con los cuadrados de las variables predictoras). Esto lo veo desde el momento que las métricas de error (MSE y MAE) tienen una gran mejora con los cuadraros de las variables predictoras y se debe porque el modelo perceptrón tiene una capacidad de aprender y explotar relaciones no lineales en los datos. Además, gracias a que puede estudiar patrones complejos en los datos de entrenamiento puede ser más efectivo para predecir datos nuevos o desconocidos.\n",
    "\n",
    "- ¿Qué modelo es mejor para los datos de criminalidad, el lineal o el perceptrón multicapa? ¿Por qué?\n",
    "\n",
    "En comparación a los datos obtenidos del modelo lineal de la actividad de **Problemas de regresión** y los de perceptrón multicapa, este último es el que resulta mejor. Porque el modelo perceptrón multicapa es más flexible y puede adaptarse a la complejidad inherente de los datos de criminalidad, que pueden estar influenciados por múltiples factores interconectados de manera no lineal y resulta más preferible debido a su capacidad para modelar relaciones complejas y no lineales como había mencionado en la anterior respuesta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kg5WrlpR3-cg"
   },
   "source": [
    "### Ejercicio 2 (50 puntos)\n",
    "En este ejercicio trabajarás con datos que vienen de un experimento en el que se midió actividad muscular con la técnica de la Electromiografía en el brazo derecho de varios participantes cuando éstos realizaban un movimiento con la mano entre siete posible (Flexionar hacia arriba, Flexionar hacia abajo, Cerrar la mano, Estirar la mano, Abrir la mano, Coger un objeto, No moverse). Al igual que en el ejercicio anterior, los datos se cargan con la función loadtxt de numpy. A su vez, la primera columna corresponde a la clase (1, 2, 3, 4, 5, 6, y 7), la segunda columna se ignora, y el resto de las columnas indican las variables que se calcularon de la respuesta muscular. El archivo de datos con el que trabajarás depende de tu matrícula.\n",
    "\n",
    "Para este conjunto de datos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6ay77io4NTJ"
   },
   "source": [
    "#### 1.- Evalúa un modelo perceptrón multicapa con validación cruzada utilizando al menos 5 capas de 20 neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = np.loadtxt('M_5.txt')\n",
    "x = df2[:,1:]\n",
    "y = df2[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4H0G0MrW3Z2B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.89      0.92      0.91        90\n",
      "         2.0       0.65      0.68      0.66        90\n",
      "         3.0       0.96      0.97      0.96        90\n",
      "         4.0       0.97      0.98      0.97        90\n",
      "         5.0       0.93      0.90      0.92        90\n",
      "         6.0       0.66      0.63      0.65        90\n",
      "         7.0       0.95      0.93      0.94        89\n",
      "\n",
      "    accuracy                           0.86       629\n",
      "   macro avg       0.86      0.86      0.86       629\n",
      "weighted avg       0.86      0.86      0.86       629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(20, 20, 20, 20, 20), max_iter=1000)\n",
    "clf.fit(x, y)\n",
    "y_pred = cross_val_predict(MLPClassifier(hidden_layer_sizes=(20, 20, 20, 20, 20),\n",
    "max_iter=10000), x, y)\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idgjPeyi5AVx"
   },
   "source": [
    "#### 2.- Evalúa un modelo perceptrón multicapa con validación cruzada, pero encontrando el número óptimo de capas y neuronas de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ae3ljbfi4_t7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(hidden_layer_sizes=[90], max_iter=10000)\n"
     ]
    }
   ],
   "source": [
    "num_layers = np.arange(1, 20, 5)\n",
    "num_neurons = np.arange(10, 110, 20)\n",
    "layers = []\n",
    "for l in num_layers:\n",
    "    for n in num_neurons:\n",
    "        layers.append(l*[n])\n",
    "clf = GridSearchCV(MLPClassifier(max_iter=10000), {'hidden_layer_sizes': layers},\n",
    "cv = 5)\n",
    "clf.fit(x, y)\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgOOHQMp5M9x"
   },
   "source": [
    "#### 3-. Prepara el modelo perceptrón multicapa:\n",
    "\n",
    "- Opten los hiperparámetros óptimos de capas y neuronas de la red.\n",
    "- Con los hiperparámetros óptimos, ajusta el modelo con todos los datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YtD8PdTE5Wfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.90      0.92      0.91        90\n",
      "         2.0       0.64      0.74      0.69        90\n",
      "         3.0       0.96      0.96      0.96        90\n",
      "         4.0       0.96      0.97      0.96        90\n",
      "         5.0       0.92      0.90      0.91        90\n",
      "         6.0       0.78      0.62      0.69        90\n",
      "         7.0       0.97      1.00      0.98        89\n",
      "\n",
      "    accuracy                           0.87       629\n",
      "   macro avg       0.87      0.87      0.87       629\n",
      "weighted avg       0.87      0.87      0.87       629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GridSearchCV(MLPClassifier(max_iter=10000), {'hidden_layer_sizes': layers},\n",
    "cv = 5)\n",
    "y_pred = cross_val_predict(clf, x, y, cv = 5)\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-. Contesta lo siguientes:\n",
    "- ¿Observas alguna mejora importante al optimizar el tamaño de la red? ¿Es el resultado que esperabas? Argumenta tu respuesta\n",
    "\n",
    "Si, se mostro una mejora importante porque cuando utilizabamos 5 capas de 20 neuronas el modelo tenia un accuracy promedio del 84% pero, cuando realice la busqueda para encontrar el número óptimo de capas y neuronas el modelo alcanzo un accuracy promedio del 87%. Quiza no sea el gran porcentaje, no obstante, si represento una mejora en el rendimiento del modelo.\n",
    "En parte si era el resultado de lo que esperaba porque es común que la optimización de la arquitectura de la red neuronal mejore el rendimiento, sin embargo, esperaba que el resultado de la precisión alcanzara un 90% al menos. Igual comprendo que el resultado siempre depende de la complejidad y naturaleza de los datos asi que los resultados obtenidos fueron decentes.\n",
    "\n",
    "- ¿Qué inconvenientes hay al encontrar el tamaño óptimo de la red? ¿Por qué?\n",
    "\n",
    "Entre los principales inconvenientes que considero que hay al encontrar el tamaño óptimo de la red son el costo computacional, el riesgo de sobreajuste y la dificultad para la interpretación. De hecho, cuando corrí el código del paso 3 si tardo alrededor de 20 minutos en ejecutar y esto se debió a que como tal la búsqueda de hiperparámetros resulto computacionalmente costosa y aunque ayuda no siempre es práctico. Acorde a lo del riesgo de sobreajuste, cuando una red demasiado grande se adapta en exceso a los datos de entrenamiento puede obtener un alto rendimiento en ellos pero un bajo rendimiento en datos no vistos. Además, redes neuronales grandes y complejas pueden ser difíciles de interpretar, lo que dificulta la comprensión de cómo toman decisiones.\n",
    "\n",
    "Desde mi punto de vista encontrar el tamaño óptimo siempre sera desafiante porque implica equilibrar la complejidad del modelo con la capacidad de generalización, recursos computacionales y la interpretabilidad del modelo."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
